\documentclass[a4paper, sans, 11pt]{moderncv}

\moderncvcolor{blue}
\moderncvstyle{banking}
 
\usepackage{multicol}
\usepackage{lipsum}
\usepackage[hyperref]{}
\usepackage[scale=0.8, top=.5cm, bottom=.5cm, left=.725cm, right=.725cm]{geometry}

\usepackage{fontawesome5}
\usepackage{lmodern}

\usepackage{etoolbox}
\patchcmd{\makehead}% <cmd>
  {1\textwidth}% <search>
  {\textwidth}% <replace>
  {}{}
  
\name{Aleksei Gregory Sorokin}{}                           
%\address{Chicago, IL, USA}{}{}
\phone[mobile]{+1~(630)~297~6261}                   
\email{agsorokin3@gmail.com}
\homepage{alegresor.github.io}
\social[linkedin]{aleksei-sorokin}
\social[github]{alegresor}
\social[googlescholar]{akk3XSEAAAAJ}
\extrainfo{US Citizen}

\usepackage[
    backend=biber,
    %defernumbers=true,
    sorting=ydnt,
    maxbibnames=99
  ]{biblatex}
\addbibresource{ags.bib}

\newcommand*{\newentry}[3][.25em]{%
  \begin{tabular}[t]{@{}p{0.15\textwidth}@{\hspace{\separatorcolumnwidth}}}%
    \raggedleft\hintstyle{#2}%
  \end{tabular}%
  \begin{tabular}[t]{@{}p{\dimexpr0.85\textwidth-\separatorcolumnwidth}@{}}
     #3
  \end{tabular}%
  \par\addvspace{#1}}

\begin{document}

\makecvtitle
\vspace{-1cm}

%\subsection{Background}
\newentry{Research}{Scientific Machine Learning, Gaussian Processes, Quasi-Monte Carlo, Probabilistic Numerics}
\newentry{Programming}{Python (PyTorch, GPyTorch, Pandas, Matplotlib), Julia, C, MATLAB, R, SQL, Wolfram} 
\newentry{Tools}{AWS (SageMaker, EC2), GitHub (general, actions, pages), \LaTeX, Docker}

\subsection{Education}
\newentry{\normalfont{2026.01 - 2028.05}}{\textbf{Postdoc.} Department of Statistics, University of Chicago. Advisors \emph{Yuehaw Khoo and Lek-Heng Lim}.}
\newentry{\normalfont{2021.08 - 2025.12}}{\textbf{PhD in Applied Math.} Illinois Institute of Technology (IIT). GPA $3.89 / 4$. Advisor \emph{Fred J Hickernell}.}
\newentry{\normalfont{2017.08 - 2021.05}}{\textbf{Master of Data Science.} IIT. Summa Cum Laude. GPA $3.94 / 4$.}
\newentry{\normalfont{2017.08 - 2021.05}}{\textbf{B.S. in Applied Math, Minor in Computer Science.} IIT. Summa Cum Laude. GPA $3.94 / 4$.}

\subsection{Experiences}
\newentry{\normalfont{2025.01 - 2025.12}}{\textbf{DOE SCGSR Fellow in Applied Math} at \textbf{Sandia National Laboratory} in Livermore, CA. I produced scientific ML models for machine-precision solutions to nonlinear PDEs \cite{bacho.CHONKNORIS}. I developed scalable multi-fidelity Gaussian processes regression models and open-source software implementations \cite{sorokin.FastBayesianMLQMC,sorokin.fastgps_probnum25}.}
\newentry{\normalfont{2024.05 - 2024.08}}{\textbf{Scientific Machine Learning Researcher} at \textbf{FM (Factory Mutual Insurance Company).} I deployed scientific ML models, including PINNs DeepONets, to accelerate CFD fire dynamics simulations \cite{sorokin.RTE_DeepONet}.}
\newentry{\normalfont{2023.05 - 2023.08}}{\textbf{Graduate Intern} at \textbf{Los Alamos National Laboratory.} I modeled multi-fidelity solutions to PDE with random coefficients using efficient and error aware Gaussian processes regression models \cite{sorokin.gp4darcy}.}
\newentry{\normalfont{2022.05 - 2022.08}}{\textbf{Givens Associate Intern} at \textbf{Argonne National Laboratory}. I derived error bounds and a sequential sampling method for efficiently estimating failure probabilities with probabilistic models \cite{sorokin.adaptive_prob_failure_GP}.}
\newentry{\normalfont{2021.05 - 2021.08}}{\textbf{ML Engineer Intern} at \textbf{SigOpt, an Intel Company}. In a six-person ML team, I contributed production code for meta-learning model-aware hyperparameter tuning via Bayesian optimization \cite{sorokin.sigopt_mulch}.}
\newentry{\normalfont{2022.09 - 2022.11}}{\textbf{Participant} in \textbf{Argonne National Laboratory's Course on AI Driven Science on Supercomputers}. Key topics included handling large scale data pipelines and parallel training for neural networks.} %\itlink{github.com/alegresor/ai-science-training-series}{https://github.com/alegresor/ai-science-training-series}.
\newentry{\normalfont{2018.05 - 2019.08}}{\textbf{Instructor} for the \textbf{STARS Computing Corps' Computer Discover Program.} I taught and developed curriculum for middle school and high school girls to learn programmatic thinking in Python.}
\newentry{\normalfont{2021.08 - 2025.01}}{\textbf{Teaching Assistant} at \textbf{IIT}. I led reviews for PhD qualifying exams in analysis and computational math.}

\subsection{Open-Source Software}
\newentry{\texttt{QMCPy}}{\textbf{Quasi-Monte Carlo Python Software} (\href{https://qmcsoftware.github.io/QMCSoftware}{qmcsoftware.github.io/QMCSoftware}). I led dozens of collaborators across academia and industry to develop QMC sequence generators, automatic variable transformations, adaptive error estimators, and diverse use cases \cite{sorokin.qmcpy_joss,sorokin.thesis,sorokin.2025.ld_randomizations_ho_nets_fast_kernel_mats,choi.challenges_great_qmc_software,choi.QMC_software,sorokin.MC_vector_functions_integrals,sorokin.QMC_IS_QMCPy,hickernell.qmc_what_why_how,jain.bernstein_betting_confidence_intervals}.}
\newentry{\texttt{FastGPs}}{\textbf{Scalable Gaussian Processes in Python} (\href{https://alegresor.github.io/fastgps}{alegresor.github.io/fastgps}). This supports GPU scaling, batched inference, hyperparameter optimization, multi-fidelity GPs, and efficient Bayesian cubature. \texttt{FastGPs} is the first package to implement GPs which require only $\mathcal{O}(n)$ storage and $\mathcal{O}(n \log n)$ computations compared to the typical  $\mathcal{O}(n^2)$ storage and $\mathcal{O}(n^3)$ computations requirements \cite{sorokin.fastgps_probnum25,sorokin.FastBayesianMLQMC}.}
\newentry{\scalebox{.9}{\texttt{QMCGenerators.jl}}}{\textbf{Randomized Quasi-Monte Carlo Sequences in Julia} (\href{https://alegresor.github.io/QMCGenerators.jl}{alegresor.github.io/QMCGenerators.jl}).}
\newentry{\texttt{QMCToolsCL}}{\textbf{Randomized Quasi-Monte Carlo Sequences in C/OpenCL} (\href{https://qmcsoftware.github.io/QMCToolsCL/}{qmcsoftware.github.io/QMCToolsCL/}).}
\newentry{\scalebox{.95}{\texttt{TorchOrthoPolys}}}{\textbf{Orthogonal Polynomials in PyTorch} (\href{https://alegresor.github.io/TorchOrthoPolys/}{alegresor.github.io/TorchOrthoPolys/}) with GPU support.}

\subsection{Awards}
\newentry{\normalfont{2025.01 - 2025.12}}{\textbf{DOE SCGSR Fellow in Applied Math}, Sandia National Laboratory, Livermore California.}
\newentry{\normalfont{2025.01}}{\textbf{Karl Menger Student Award for Exceptional Scholarship (Graduate)}, IIT.}
\newentry{\normalfont{2024.01}}{\textbf{College of Computing Excellence in Dissertation Research}, IIT.}
\newentry{\normalfont{2024}}{\textbf{Teaching Assistant Award}, IIT.}
\newentry{\normalfont{2023.08}}{\textbf{Outstanding Math Poster}, Los Alamos National Laboratory.}
% \newentry{\normalfont{2021}}{\textbf{Best Manuscript}, IIT Undergraduate Research Journal.}
% \newentry{\normalfont{2020}}{\textbf{Karl Menger Student Award for Exceptional Scholarship (Undergraduate)}, IIT.}
\newentry{\normalfont{2017.08 - 2025.05}}{\textbf{Deans List Member}, IIT, every semester.}

\subsection{References}
\newentry{\normalfont{PhD Advisor}}{\textbf{Fred J. Hickernell} (\href{mailto:hickernell@iit.edu}{hickernell@iit.edu}) Vice Provost for Research and Professor of Applied Math, IIT.}
\newentry{\normalfont{Mentor}}{\textbf{Nicolas W. Hengartner} (\href{mailto:nickh@lanl.gov}{nickh@lanl.gov}) Senior Scientist, Los Alamos National Lab.}
\newentry{\normalfont{Mentor}}{\textbf{Michael J. McCourt} (\href{mailto:mikemccourt1234@gmail.com}{mikemccourt1234@gmail.com}) CTO and Co-Founder at Distributional.}
\newentry{\normalfont{Mentor}}{\textbf{Pieterjan M. Robbe} (\href{pmrobbe@sandia.gov}{pmrobbe@sandia.gov}) Senior Member of Technical Staff, Sandia National Lab.}
% \newentry{\normalfont{Mentor}}{\textbf{Vishwas Rao, PhD} (\href{mailto:vhebbur@anl.gov}{vhebbur@anl.gov}) Assistant Computational Mathematician, Argonne National Lab.}

% \subsection{Coursework}
% \newentry{Math}{
%     Applied Analysis I/II,
%     Computational Math,
%     Probability, 
%     Statistics, 
%     Applied Statistics,
%     Bayesian Computational Statistics, 
%     Statistical Learning, 
%     Monte Carlo Methods in Finance,
%     Mathematical Methods for Algorithmic Trading,
%     Numerical Methods for PDEs,
%     Reliable Mathematical Software, 
%     Linear Optimization, 
%     Computational Algebraic Geometry} 
% \newentry{Computer Science}{
%     Big Data Technologies,
%     Data Preparation and Analysis,
%     Database Organization,
%     Big Data Visualization,
%     Systems Programming, 
%     Computer Organization and Assembly,
%     Data Structures and Algorithms, 
%     Object Oriented Programming I/II.}

%%%%% COVER LETTER
%\clearpage
%\recipient{HR Department}{Corporation\\123 Pleasant Lane\\12345 City, State} % Letter recipient
%\date{\today} % Letter date
%\opening{Dear Sir or Madam,} % Opening greeting
%\closing{Sincerely yours,} % Closing phrase
%\enclosure[Attached]{curriculum vit\ae{}} % List of enclosed documents
%\makelettertitle % Print letter title
%\lipsum[1-3] % Dummy text
%\makeletterclosing % Print letter signature

\nocite{
  sorokin.qmcpy_joss,
  sorokin.thesis,
  sorokin.fastgps_probnum25,
  hickernell.qmc_what_why_how,
  sorokin.MC_vector_functions_integrals,
  choi.challenges_great_qmc_software,
  choi.QMC_software,
  sorokin.QMC_IS_QMCPy,
  sorokin.RTE_DeepONet,
  sorokin.sigopt_mulch,
  sorokin.gp4darcy,
  gjergo.GalCEM1,
  GalCEM.software,
  gjergo2025massive,
  sorokin.2025.ld_randomizations_ho_nets_fast_kernel_mats,
  sorokin.adaptive_prob_failure_GP,
  jain.bernstein_betting_confidence_intervals,
  sorokin.FastBayesianMLQMC,
  bacho.CHONKNORIS,
}

\printbibliography[title={Publications}]

\end{document}
